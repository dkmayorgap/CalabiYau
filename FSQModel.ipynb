{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "036252ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, glob\n",
    "tfk = tf.keras\n",
    "\n",
    "# ML\n",
    "import sys\n",
    "from cymetric.models.tfhelper import prepare_tf_basis, train_model\n",
    "\n",
    "# training\n",
    "from cymetric.models.tfmodels import PhiFSModel\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "from utils import eijk\n",
    "\n",
    "from models import ProjectiveSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8e2226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = 'QuinticData'\n",
    "data = np.load(os.path.join(dirname, 'dataset.npz'))\n",
    "BASIS = np.load(os.path.join(dirname, 'basis.pickle'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a71f40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cymetric.models.tfhelper import prepare_tf_basis, train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2039e07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASIS = prepare_tf_basis(BASIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e856c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017621975"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kappa = np.real(BASIS['KAPPA'].numpy());\n",
    "kappa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caeb7089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cymetric.models.callbacks import RicciCallback, SigmaCallback, VolkCallback, KaehlerCallback, TransitionCallback\n",
    "from cymetric.models.tfmodels import MultFSModel\n",
    "from cymetric.models.metrics import SigmaLoss, KaehlerLoss, TransitionLoss, VolkLoss, RicciLoss, TotalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6101837",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcb = RicciCallback((data['X_val'], data['y_val']), data['val_pullbacks'])\n",
    "scb = SigmaCallback((data['X_val'], data['y_val']))\n",
    "volkcb = VolkCallback((data['X_val'], data['y_val']))\n",
    "kcb = KaehlerCallback((data['X_val'], data['y_val']))\n",
    "tcb = TransitionCallback((data['X_val'], data['y_val']))\n",
    "cb_list = [rcb, scb, kcb, tcb, volkcb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acb3d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlayer = 3\n",
    "nHidden = 64\n",
    "act = 'gelu'\n",
    "nEpochs = 5\n",
    "bSizes = [64, 5000]\n",
    "alpha = [1., 1., 1., 1., 1.]\n",
    "nfold = 3\n",
    "n_in = 2*5\n",
    "n_out = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e45bed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = tf.keras.Sequential()\n",
    "nn.add(tfk.Input(shape=(n_in)))\n",
    "for i in range(nlayer):\n",
    "    nn.add(tfk.layers.Dense(nHidden, activation=act))\n",
    "nn.add(tfk.layers.Dense(n_out, use_bias=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81d2ac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmodel = PhiFSModel(nn, BASIS, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0aa73f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmetrics = [TotalLoss(), SigmaLoss(), KaehlerLoss(), TransitionLoss(), VolkLoss(), RicciLoss()]\n",
    "opt = tfk.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01c4dfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/5\n",
      "6250/6250 [==============================] - 57s 8ms/step - loss: 0.1670 - sigma_loss: 0.1639 - kaehler_loss: 0.0000e+00 - transition_loss: 0.0031 - volk_loss: 0.0000e+00 - ricci_loss: 0.0000e+00\n",
      "80/80 [==============================] - 36s 392ms/step - loss: 0.2412 - sigma_loss: 0.1527 - kaehler_loss: 0.0000e+00 - transition_loss: 0.0000e+00 - volk_loss: 0.0885 - ricci_loss: 0.0000e+00\n",
      "WARNING:tensorflow:Using a while_loop for converting ScatterNd\n",
      " - Ricci measure val:      1.2433\n",
      " - Sigma measure val:      0.1428\n",
      " - Kaehler measure val:    9.9124e-16\n",
      " - Transition measure val: 0.0027\n",
      " - Volk val:               5.1413\n",
      "\n",
      "Epoch  2/5\n",
      "6250/6250 [==============================] - 56s 8ms/step - loss: 0.0998 - sigma_loss: 0.0975 - kaehler_loss: 0.0000e+00 - transition_loss: 0.0023 - volk_loss: 0.0000e+00 - ricci_loss: 0.0000e+00\n",
      "80/80 [==============================] - 36s 412ms/step - loss: 0.1010 - sigma_loss: 0.0511 - kaehler_loss: 0.0000e+00 - transition_loss: 0.0000e+00 - volk_loss: 0.0499 - ricci_loss: 0.0000e+00\n",
      " - Ricci measure val:      0.2173\n",
      " - Sigma measure val:      0.0427\n",
      " - Kaehler measure val:    1.4002e-15\n",
      " - Transition measure val: 0.0019\n",
      " - Volk val:               5.1116\n",
      "\n",
      "Epoch  3/5\n",
      "6250/6250 [==============================] - 56s 8ms/step - loss: 0.0405 - sigma_loss: 0.0393 - kaehler_loss: 0.0000e+00 - transition_loss: 0.0012 - volk_loss: 0.0000e+00 - ricci_loss: 0.0000e+00\n",
      "80/80 [==============================] - 36s 407ms/step - loss: 0.1035 - sigma_loss: 0.0361 - kaehler_loss: 0.0000e+00 - transition_loss: 0.0000e+00 - volk_loss: 0.0674 - ricci_loss: 0.0000e+00\n",
      " - Ricci measure val:      0.1176\n",
      " - Sigma measure val:      0.0224\n",
      " - Kaehler measure val:    1.3729e-15\n",
      " - Transition measure val: 9.1029e-04\n",
      " - Volk val:               4.9090\n",
      "\n",
      "Epoch  4/5\n",
      "6250/6250 [==============================] - 58s 9ms/step - loss: 0.0281 - sigma_loss: 0.0274 - kaehler_loss: 0.0000e+00 - transition_loss: 6.4036e-04 - volk_loss: 0.0000e+00 - ricci_loss: 0.0000e+00\n",
      "80/80 [==============================] - 35s 400ms/step - loss: 0.0570 - sigma_loss: 0.0233 - kaehler_loss: 0.0000e+00 - transition_loss: 0.0000e+00 - volk_loss: 0.0337 - ricci_loss: 0.0000e+00\n",
      " - Ricci measure val:      0.1037\n",
      " - Sigma measure val:      0.0159\n",
      " - Kaehler measure val:    1.3356e-15\n",
      " - Transition measure val: 5.2907e-04\n",
      " - Volk val:               4.9579\n",
      "\n",
      "Epoch  5/5\n",
      "6250/6250 [==============================] - 56s 8ms/step - loss: 0.0232 - sigma_loss: 0.0228 - kaehler_loss: 0.0000e+00 - transition_loss: 4.6079e-04 - volk_loss: 0.0000e+00 - ricci_loss: 0.0000e+00\n",
      "80/80 [==============================] - 35s 405ms/step - loss: 0.0582 - sigma_loss: 0.0212 - kaehler_loss: 0.0000e+00 - transition_loss: 0.0000e+00 - volk_loss: 0.0369 - ricci_loss: 0.0000e+00\n",
      " - Ricci measure val:      0.0973\n",
      " - Sigma measure val:      0.0131\n",
      " - Kaehler measure val:    1.2860e-15\n",
      " - Transition measure val: 4.2076e-04\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x000002D01B42D280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      " - Volk val:               4.9342\n"
     ]
    }
   ],
   "source": [
    "fmodel, training_history = train_model(fmodel, data, optimizer=opt, epochs=nEpochs, batch_sizes=[64, 5000], \n",
    "                                       verbose=1, custom_metrics=cmetrics, callbacks=cb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa69ea9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3.6117253955428716-1.9305438481768693e-09j)\n"
     ]
    }
   ],
   "source": [
    "x_vars = tf.cast(tf.constant(data[\"X_train\"]), tf.float32)\n",
    "weights, omegas = data['y_train'][:,-2], data['y_train'][:,-1]\n",
    "\n",
    "print(np.mean(weights * np.linalg.det(fmodel(x_vars))/ omegas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2182e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 3), dtype=complex64, numpy=\n",
       "array([[[ 0.09253744-7.5669959e-10j,  0.00856687-1.9730455e-03j,\n",
       "         -0.00577878-2.5402289e-02j],\n",
       "        [ 0.00856686+1.9730462e-03j,  0.07905391+1.5870683e-10j,\n",
       "          0.00865713+1.0466812e-02j],\n",
       "        [-0.00577878+2.5402287e-02j,  0.00865713-1.0466811e-02j,\n",
       "          0.07936295+6.9849193e-10j]]], dtype=complex64)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmodel(x_vars[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d2e2dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([400000, 10])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ae97fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[ 5.9635967e-01, -2.0448701e-01,  8.1529528e-01,  1.0000000e+00,\n",
       "         7.5759637e-01, -4.6444046e-01,  3.4482372e-01,  5.0856006e-01,\n",
       "        -3.4694470e-18, -2.3732327e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vars[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af59c468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1311b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ricci_scalar_fn(model, points, pullbacks=None, verbose=0, rdet=True):\n",
    "    r\"\"\"Computes the Ricci scalar for a kaehler metric.\n",
    "\n",
    "    .. math::\n",
    "        R = g^{ij} \\partial_i \\bar{\\partial}_j \\log \\det g\n",
    "\n",
    "    Args:\n",
    "        model (tfk.model): Any (sub-)class of FSModel.\n",
    "        points (tensor[(n_p,2*ncoord), tf.float32]): NN input\n",
    "        pullbacks (tensor[(n_p,nfold,ncoord), tf.complex64]): Pullback tensor. Defaults to None. Then gets computed.\n",
    "        verbose (int, optional): if > 0 prints some intermediate infos. Defaults to 0.\n",
    "        rdet (bool, optional): if True also returns det. Defaults to True.\n",
    "            This is a bit hacky, because the output signature changes\n",
    "            but avoids recomputing the determinant after batching.\n",
    "\n",
    "    Returns:\n",
    "        tf.float32(tensor[(n_p,), tf.float32]): Ricci scalar\n",
    "    \"\"\"\n",
    "    ncoords = model.ncoords\n",
    "    x_vars = points\n",
    "    if pullbacks is None:\n",
    "        pullbacks = model.pullbacks(points)\n",
    "    # take derivatives\n",
    "    with tf.GradientTape(persistent=True) as tape1:\n",
    "        tape1.watch(x_vars)\n",
    "        with tf.GradientTape(persistent=True) as tape2:\n",
    "            tape2.watch(x_vars)\n",
    "            prediction = model(x_vars)\n",
    "            det = tf.math.real(tf.linalg.det(prediction)) * 1.  # factorial / (2**nfold)\n",
    "            log = tf.math.log(det)\n",
    "        di_dg = tape2.gradient(log, x_vars)\n",
    "    didj_dg = tf.cast(tape1.batch_jacobian(di_dg, x_vars), dtype=tf.complex64)\n",
    "    # add derivatives together to complex tensor\n",
    "    ricci_ij = didj_dg[:, 0:ncoords, 0:ncoords]\n",
    "    ricci_ij += 1j * didj_dg[:, 0:ncoords, ncoords:]\n",
    "    ricci_ij -= 1j * didj_dg[:, ncoords:, 0:ncoords]\n",
    "    ricci_ij += didj_dg[:, ncoords:, ncoords:]\n",
    "    ricci_ij *= 0.25\n",
    "    pred_inv = tf.linalg.inv(prediction)\n",
    "    ricci_scalar = tf.einsum('xba,xai,xij,xbj->x', pred_inv, pullbacks,\n",
    "                             ricci_ij, tf.math.conj(pullbacks))\n",
    "    ricci_scalar = tf.math.real(ricci_scalar)\n",
    "    if verbose > 0:\n",
    "        tf.print(' - Avg ricci scalar is',\n",
    "                 tf.math.reduce_mean(ricci_scalar), output_stream=sys.stdout)\n",
    "        if verbose > 1:\n",
    "            tf.print(' - Max ricci scalar is',\n",
    "                     tf.reduce_max(ricci_scalar), output_stream=sys.stdout)\n",
    "            tf.print(' - Min ricci scalar is',\n",
    "                     tf.reduce_min(ricci_scalar), output_stream=sys.stdout)\n",
    "    if rdet:\n",
    "        return ricci_scalar, det\n",
    "    else:\n",
    "        return ricci_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22c10bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "riem = None\n",
    "getNum = lambda x: int(x.split('/')[1].split('.')[0][4:])\n",
    "files = sorted(glob.glob(\"riemvalues/*.npy\"), key = getNum)\n",
    "for riemfile in files:\n",
    "    if riem is None:\n",
    "        riem = np.load(riemfile)\n",
    "    else:\n",
    "        riem = np.append(riem, np.load(riemfile), axis=0)\n",
    "riem = np.asarray(riem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7764d7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ScatterNd\n",
      "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([8.097036], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.00049893], dtype=float32)>)\n",
      "WARNING:tensorflow:Using a while_loop for converting ScatterNd\n",
      "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([-21.19727], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.00095881], dtype=float32)>)\n",
      "WARNING:tensorflow:Using a while_loop for converting ScatterNd\n",
      "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([-13.258491], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.00165956], dtype=float32)>)\n",
      "WARNING:tensorflow:Using a while_loop for converting ScatterNd\n",
      "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([-7.197782], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.00073135], dtype=float32)>)\n",
      "WARNING:tensorflow:Using a while_loop for converting ScatterNd\n",
      "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([-27.086912], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.00093361], dtype=float32)>)\n",
      "WARNING:tensorflow:Using a while_loop for converting ScatterNd\n",
      "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([-18.343073], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.00115545], dtype=float32)>)\n",
      "WARNING:tensorflow:Using a while_loop for converting ScatterNd\n",
      "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([4.6172028], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.00082622], dtype=float32)>)\n",
      "WARNING:tensorflow:Using a while_loop for converting ScatterNd\n",
      "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([25.05534], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.00039564], dtype=float32)>)\n",
      "WARNING:tensorflow:Using a while_loop for converting ScatterNd\n",
      "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([15.275155], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.00042992], dtype=float32)>)\n",
      "WARNING:tensorflow:Using a while_loop for converting ScatterNd\n",
      "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.655695], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.00053624], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "ltot=10\n",
    "for k in range(ltot):\n",
    "    print(ricci_scalar_fn(fmodel,x_vars[k:k+1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f35e30a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 0-dimensional, but 1 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mricurv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 0-dimensional, but 1 were indexed"
     ]
    }
   ],
   "source": [
    "ricurv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35bb3909",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type NoneType).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m c3 \u001b[38;5;241m=\u001b[39m ProjectiveSpace\u001b[38;5;241m.\u001b[39mgetC3(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mriem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplex128\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      2\u001b[0m c3_top \u001b[38;5;241m=\u001b[39m ProjectiveSpace\u001b[38;5;241m.\u001b[39mgetTopNumber(c3)\n\u001b[0;32m      4\u001b[0m norm_factor \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1\u001b[39mj)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mfactorial(\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cymetric\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cymetric\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:988\u001b[0m, in \u001b[0;36mcast\u001b[1;34m(x, dtype, name)\u001b[0m\n\u001b[0;32m    982\u001b[0m   x \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mIndexedSlices(values_cast, x\u001b[38;5;241m.\u001b[39mindices, x\u001b[38;5;241m.\u001b[39mdense_shape)\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    984\u001b[0m   \u001b[38;5;66;03m# TODO(josh11b): If x is not already a Tensor, we could return\u001b[39;00m\n\u001b[0;32m    985\u001b[0m   \u001b[38;5;66;03m# ops.convert_to_tensor(x, dtype=dtype, ...)  here, but that\u001b[39;00m\n\u001b[0;32m    986\u001b[0m   \u001b[38;5;66;03m# allows some conversions that cast() can't do, e.g. casting numbers to\u001b[39;00m\n\u001b[0;32m    987\u001b[0m   \u001b[38;5;66;03m# strings.\u001b[39;00m\n\u001b[1;32m--> 988\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    989\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype \u001b[38;5;241m!=\u001b[39m base_type:\n\u001b[0;32m    990\u001b[0m     x \u001b[38;5;241m=\u001b[39m gen_math_ops\u001b[38;5;241m.\u001b[39mcast(x, base_type, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cymetric\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:163\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cymetric\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1566\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1561\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor did not convert to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1562\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe preferred dtype: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1563\u001b[0m                       (ret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype, preferred_dtype\u001b[38;5;241m.\u001b[39mbase_dtype))\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1566\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m   1569\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cymetric\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:52\u001b[0m, in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_default_conversion_function\u001b[39m(value, dtype, name, as_ref):\n\u001b[0;32m     51\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m as_ref  \u001b[38;5;66;03m# Unused.\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cymetric\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:271\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    176\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cymetric\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:283\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    282\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 283\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[0;32m    286\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cymetric\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:308\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    307\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 308\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    309\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cymetric\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:106\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    105\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type NoneType)."
     ]
    }
   ],
   "source": [
    "c3 = ProjectiveSpace.getC3(tf.cast(riem, tf.complex128))\n",
    "c3_top = ProjectiveSpace.getTopNumber(c3)\n",
    "\n",
    "norm_factor = (-2*1j)**3 / np.math.factorial(3)\n",
    "print(f\"Int_X c3 = {np.real(norm_factor * np.mean(weights * c3_top / omegas))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed275321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cymetric] *",
   "language": "python",
   "name": "conda-env-cymetric-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
